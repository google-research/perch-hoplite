{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndV0dmyzhpHE"
      },
      "source": [
        "# Call density estimation\n",
        "\n",
        "This notebook provides tools for performing call density analyses using a custom classifier.\n",
        "\n",
        "See the \"All Thresholds Barred\" paper for our call density methodology: https://arxiv.org/abs/2402.15360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN69E14wNBUW"
      },
      "outputs": [],
      "source": [
        "# @title Installation {vertical-output: true}\n",
        "\n",
        "# @markdown You will likely need to work with `01_embed_audio.ipynb` and/or\n",
        "# @markdown `02_agile_modeling.ipynb` before working with this notebook.\n",
        "# @markdown\n",
        "# @markdown Run this notebook in Google Colab by following\n",
        "# @markdown [this link](https://github.com/google-research/perch-hoplite/blob/main/perch_hoplite/agile/03_call_density.ipynb).\n",
        "# @markdown\n",
        "# @markdown Run this cell to install the project dependencies.\n",
        "\n",
        "!pip install git+https://github.com/google-research/perch-hoplite.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from ml_collections import config_dict\n",
        "import numpy as np\n",
        "\n",
        "from perch_hoplite.agile import audio_loader\n",
        "from perch_hoplite.agile import call_density\n",
        "from perch_hoplite.agile import classifier\n",
        "from perch_hoplite.agile import embed\n",
        "from perch_hoplite.agile import embedding_display\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db import interface\n",
        "from perch_hoplite.db import sqlite_usearch_impl"
      ],
      "metadata": {
        "id": "dXdfNqR4hwgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Connect to database {vertical-output: true}\n",
        "\n",
        "# @markdown Location of database containing audio embeddings:\n",
        "db_path = \"/tmp/hoplite\"  # @param {type: \"string\"}\n",
        "db = sqlite_usearch_impl.SQLiteUSearchDB.create(db_path)\n",
        "\n",
        "all_classes = db.get_all_labels()\n",
        "print(\"Existing db classes:\\n\")\n",
        "for idx, c in enumerate(all_classes):\n",
        "  print(f\"{idx:3d}: {c}\", end=(\"\\n\" if (idx + 1) % 5 == 0 else \"\\t\"))"
      ],
      "metadata": {
        "id": "pMKjiG8Ph0Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load agile classifier {vertical-output: true}\n",
        "\n",
        "# @markdown Location of agile classifier:\n",
        "agile_classifier_path = \"/tmp/hoplite/agile_classifier_v2.pt\"  # @param {type: \"string\"}\n",
        "agile_classifier = classifier.LinearClassifier.load(agile_classifier_path)\n",
        "\n",
        "embed_config = db.get_metadata(\"audio_sources\")\n",
        "audio_sources = source_info.AudioSources.from_config_dict(embed_config)\n",
        "window_size_s = agile_classifier.embedding_model_config.model_config.get(\"window_size_s\", 5.0)\n",
        "sample_rate = agile_classifier.embedding_model_config.model_config.sample_rate\n",
        "audio_filepath_loader = audio_loader.make_filepath_loader(\n",
        "    audio_sources=audio_sources,\n",
        "    window_size_s=window_size_s,\n",
        "    sample_rate_hz=sample_rate,\n",
        ")"
      ],
      "metadata": {
        "id": "DC8We3J2Zm2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set up new call density study {vertical-output: true}\n",
        "\n",
        "# @markdown Pick a study name:\n",
        "study_name = \"all_thresholds_barred\"  # @param {type: \"string\"}\n",
        "\n",
        "# @markdown Pick a target class:\n",
        "target_class = \"amerob\"  # @param {type: \"string\"}\n",
        "target_class_idx = all_classes.index(target_class)\n",
        "\n",
        "# @markdown Pick some quantile bounds for validation. Should be an ordered list,\n",
        "# @markdown beginning with 0.0 and ending with 1.0.\n",
        "quantile_bounds = [0.0, 0.5, 0.75, 0.875, 1.0]  # @param\n",
        "\n",
        "# @markdown Pick the number of samples to validate per bin:\n",
        "samples_per_bin = 25  # @param\n",
        "\n",
        "# @markdown Pick a random seed for shuffling:\n",
        "random_seed = 42  # @param\n",
        "\n",
        "# Select and shuffle window ids. Here we're selecting all window ids from the\n",
        "# database, to \"simulate\" classifier mistakes.\n",
        "deployments_filter = None\n",
        "recordings_filter = None\n",
        "windows_filter = None\n",
        "annotations_filter = None\n",
        "window_ids = db.match_window_ids(\n",
        "    deployments_filter=deployments_filter,\n",
        "    recordings_filter=recordings_filter,\n",
        "    windows_filter=windows_filter,\n",
        "    annotations_filter=annotations_filter,\n",
        ")\n",
        "rng = np.random.default_rng(random_seed)\n",
        "rng.shuffle(window_ids)\n",
        "\n",
        "# @markdown Pick an optional sample size. If set to `0`, all matching windows are binned.\n",
        "sample_size = 0  # @param {type: \"number\"}\n",
        "\n",
        "# Truncate number of matching windows.\n",
        "if sample_size > 0:\n",
        "  window_ids = window_ids[:sample_size]\n",
        "\n",
        "# Compute logits for matching windows.\n",
        "logits = []\n",
        "for window_ids_batch in embed.batched(window_ids, 256):\n",
        "  embeddings_batch = db.get_embeddings_batch(window_ids_batch)\n",
        "  logits_batch = agile_classifier(embeddings_batch)\n",
        "  logits_batch = logits_batch[..., target_class_idx]\n",
        "  logits.extend(logits_batch)\n",
        "\n",
        "# Get existing annotations for validation examples from the database.\n",
        "# If more than one annotation is present, we pick the last one.\n",
        "annotations = []\n",
        "for window_id in window_ids:\n",
        "  window = db.get_window(window_id)\n",
        "  recording = db.get_recording(window.recording_id)\n",
        "  matching_annotations = db.get_all_annotations(\n",
        "      filter=config_dict.create(\n",
        "          eq=dict(\n",
        "              recording_id=window.recording_id,\n",
        "              label=target_class,\n",
        "          ),\n",
        "          approx=dict(offsets=window.offsets),\n",
        "      )\n",
        "  )\n",
        "  annotations.append(\n",
        "      matching_annotations[-1]  # Pick last match.\n",
        "      if matching_annotations\n",
        "      else None\n",
        "  )\n",
        "\n",
        "# Compile all info into a call density study that can be stored in the database\n",
        "# and later iterated on.\n",
        "study = call_density.CallDensityConfig(\n",
        "    study_name=study_name,\n",
        "    classifier=agile_classifier.to_config_dict(),\n",
        "    target_class=target_class,\n",
        "    quantile_bounds=quantile_bounds,\n",
        "    samples_per_bin=samples_per_bin,\n",
        "    window_ids=window_ids,\n",
        "    logits=logits,\n",
        "    annotations=annotations,\n",
        "    deployments_filter=deployments_filter,\n",
        "    recordings_filter=recordings_filter,\n",
        "    windows_filter=windows_filter,\n",
        "    annotations_filter=annotations_filter,\n",
        ")\n",
        "\n",
        "# Plot logits distribution.\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\n",
        "    f\"Logits distribution ({study.target_class})\"\n",
        "    f\"\\nquantile bounds: {study.quantile_bounds}\"\n",
        "    f\"\\nvalue bounds: {[round(float(v), 2) for v in study.value_bounds]}\"\n",
        ")\n",
        "ax.set_xlabel(\"logits\")\n",
        "ys, _, _, = ax.hist(logits, bins=100, density=True)\n",
        "for q in study.value_bounds:\n",
        "  ax.plot([q, q], [0.0, np.max(ys)], \"k:\", alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Plot logits distribution by bin.\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title(f\"Logits distribution by bin ({study.target_class})\")\n",
        "ax.set_xlabel(\"bins\")\n",
        "ax.set_ylabel(\"bin sizes\")\n",
        "bin_names = [str(b) for b in study.bins_dict.keys()]\n",
        "bin_sizes = [len(b) for b in study.bins_dict.values()]\n",
        "ax.bar(bin_names, bin_sizes)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R7U6VrIvcN7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save study in the database {vertical-output: true}\n",
        "\n",
        "try:\n",
        "  call_density_configs = db.get_metadata(\"call_density_configs\")\n",
        "except KeyError:\n",
        "  call_density_configs = config_dict.create()\n",
        "\n",
        "study_db_key = f\"{study_name}/{target_class}\"\n",
        "call_density_configs[study_db_key] = study.to_config_dict()\n",
        "\n",
        "db.insert_metadata(\"call_density_configs\", call_density_configs)\n",
        "db.commit()\n",
        "print(\"Call density study saved to database:\", study_db_key)"
      ],
      "metadata": {
        "id": "ejEaFrKJ6L3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display results for validation {vertical-output: true}\n",
        "\n",
        "results = study.convert_bins_to_search_results()\n",
        "display_results = embedding_display.EmbeddingDisplayGroup.from_search_results(\n",
        "    results,\n",
        "    db,\n",
        "    sample_rate_hz=32000,\n",
        "    frame_rate=100,\n",
        "    audio_loader=audio_filepath_loader,\n",
        ")\n",
        "display_results.display(positive_labels=[target_class])"
      ],
      "metadata": {
        "id": "s7qrzS0wXFO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save validation data {vertical-output: true}\n",
        "\n",
        "# @markdown Choose an annotator name:\n",
        "annotator_id = \"linnaeus\"  # @param {type: \"string\"}\n",
        "\n",
        "annotations_dict = display_results.harvest_annotated_windows(annotator_id, skip_uncertain=False)\n",
        "\n",
        "# Save annotations in the database.\n",
        "for window_id, ann_list in annotations_dict.items():\n",
        "  for ann in ann_list:\n",
        "    db.insert_annotation(\n",
        "        recording_id=ann.recording_id,\n",
        "        offsets=ann.offsets,\n",
        "        label=ann.label,\n",
        "        label_type=ann.label_type,\n",
        "        provenance=ann.provenance,\n",
        "        handle_duplicates=\"skip\",\n",
        "    )\n",
        "    print(\"Saved new annotation:\", ann)\n",
        "\n",
        "# Update validation examples from annotations.\n",
        "study.update_from_annotated_windows(annotations_dict)\n",
        "call_density_configs[study_db_key] = study.to_config_dict()\n",
        "db.insert_metadata(\"call_density_configs\", call_density_configs)\n",
        "\n",
        "# Commit db changes.\n",
        "db.commit()"
      ],
      "metadata": {
        "id": "6lyMmuvIhnJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5069a759"
      },
      "cell_type": "code",
      "source": [
        "# @title Estimate call density and ROC-AUC {vertical-output: true}\n",
        "\n",
        "validation_examples = study.select_validation_examples(\n",
        "    label_types=[interface.LabelType.POSITIVE, interface.LabelType.NEGATIVE]\n",
        ")\n",
        "density_ev , density_samples = call_density.estimate_call_density(\n",
        "    validation_examples)\n",
        "\n",
        "# Plot call density estimate.\n",
        "plt.figure(figsize=(10, 5))\n",
        "xs, ys, _ = plt.hist(density_samples, density=True, bins=25, alpha=0.25)\n",
        "plt.plot([density_ev, density_ev], [0.0, np.max(xs)], \"k:\", alpha=0.75,\n",
        "         label=\"density_ev\")\n",
        "\n",
        "low, high = np.quantile(density_samples, [0.05, 0.95])\n",
        "plt.plot([low, low], [0.0, np.max(xs)], \"g\", alpha=0.75, label=\"low conf\")\n",
        "plt.plot([high, high], [0.0, np.max(xs)], \"g\", alpha=0.75, label=\"high conf\")\n",
        "\n",
        "plt.xlim(0.0, 1.0)\n",
        "plt.xlabel(\"Call Rate (q)\")\n",
        "plt.ylabel(\"P(q)\")\n",
        "plt.title(f\"Call Density Estimation ({target_class})\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"EV Call Density: {density_ev:.4f}\")\n",
        "print(f\"(Low/EV/High) Call Density Estimate: ({low:5.4f} / {density_ev:5.4f} / {high:5.4f})\")\n",
        "\n",
        "roc_auc_estimate = call_density.estimate_roc_auc(validation_examples)\n",
        "print(f\"Estimated ROC-AUC : {roc_auc_estimate:5.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "last_runtime": {
        "build_target": "//third_party/py/chirp:colab_binary",
        "kind": "private"
      },
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
